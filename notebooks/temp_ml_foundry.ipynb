{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13b25966",
   "metadata": {},
   "source": [
    "# Business Problem\n",
    "\n",
    "1. **Objective**\n",
    "   - To classifiy an image into 3 categories: Driving License, Social Security Card, Other\n",
    "   - Learn from images and its properties to classify into the respective categories better\n",
    "\n",
    "\n",
    "2. **Machine Learning Problem**\n",
    "   - Develop a machine learning model based on convolution neural network to learn properties of the 3 categories of images and predict accurately for new image\n",
    "\n",
    "\n",
    "3. **Technology**\n",
    "   - Python, Scikit-learn, tensorflow, keras, Numpy\n",
    "   \n",
    "\n",
    "4. **Decision making**\n",
    "   - Select the best model which performs the best w.r.t classification accuracy\n",
    "   - Metrics: Accuracy\n",
    "   \n",
    "\n",
    "5. **Deployment**\n",
    "   - Deploy model in a scalable way so that business decisions can be taken in near real time to classify images\n",
    "\n",
    "\n",
    "\n",
    "**Dataset**<br>\n",
    "driving_license images<br>\n",
    "social_security images<br>\n",
    "other images<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e3baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.21.5\n",
    "!pip install keras==2.7.0\n",
    "!pip install tensorflow==2.7.0\n",
    "!pip install matplotlib==3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad396a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "from io import BytesIO\n",
    "folder = urllib.request.urlopen('https://s3.amazonaws.com/projex.dezyre.com/cnn-models-for-image-classification-in-python/materials/data.zip')\n",
    "zipfile = ZipFile(BytesIO(folder.read()))\n",
    "zipfile.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfile.extractall('input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35509a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"input/Training_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915521e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_license = list(data_dir.glob('driving_license/*'))\n",
    "social_security = list(data_dir.glob('social_security/*'))\n",
    "others = list(data_dir.glob('others/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24503bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(str(driving_license[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a9737",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(str(social_security[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(str(others[140]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11413f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de87d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d480b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa31682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b998e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d644a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b69e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=20\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad854f1",
   "metadata": {},
   "source": [
    "## Login to TrueFoundry  ðŸŽ‰\n",
    "\n",
    "1. An account with  <a href=\"https://projectpro.truefoundry.com/signin\">TrueFoundry</a>. has been created with the same email address that you use to sign in to ProjectPro and an email has been sent to you to set your password. \n",
    "2. Please go to your inbox and follow the link to make sure you are logged into TrueFoundry before getting to the next cell. If you don't see the email in your inbox, please check your Spam folder. \n",
    "\n",
    "Note: If you are not able to signin or did not receive an email, please send an email to nikunj@truefoundry.com with the following subject- \"ProjectPro User: TrueFoundry Login Issue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d623171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade mlfoundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb29da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlfoundry as mlf\n",
    "\n",
    "TRACKING_URL = 'https://projectpro.truefoundry.com'\n",
    "mlf_api = mlf.get_client(TRACKING_URL)\n",
    "\n",
    "mlf_run = mlf_api.create_run(\"cnn-project\", \"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6210903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a67fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in epochs_range:\n",
    "    metrics_dict = {\n",
    "        \"acc\": acc[i],\n",
    "        \"val_acc\": val_acc[i],\n",
    "        \"loss\": loss[i],\n",
    "        \"val_loss\": val_loss[i]\n",
    "    }\n",
    "    mlf_run.log_metrics(metrics_dict, step=i)\n",
    "\n",
    "params_dict = {\n",
    "    \"layer-1-chnnels\": 16,\n",
    "    \"layer-2-chnnels\": 32,\n",
    "    \"layer-3-chnnels\": 64,\n",
    "    \"layer-4-chnnels\": 128,\n",
    "    \n",
    "}\n",
    "mlf_run.log_params(params_dict)\n",
    "\n",
    "mlf_run.log_model(model, \"keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cba27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380751b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b494746",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f00ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd44225",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bbc78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"cnn-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"output/cnn-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cabbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7132a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(\"cnn-project\", \"cnn-with-augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c178c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in epochs_range:\n",
    "    metrics_dict = {\n",
    "        \"acc\": acc[i],\n",
    "        \"val_acc\": val_acc[i],\n",
    "        \"loss\": loss[i],\n",
    "        \"val_loss\": val_loss[i]\n",
    "    }\n",
    "    mlf_run.log_metrics(metrics_dict, step=i)\n",
    "\n",
    "params_dict = {\n",
    "    \"layer-1-chnnels\": 16,\n",
    "    \"layer-2-chnnels\": 32,\n",
    "    \"layer-3-chnnels\": 64,\n",
    "    \"layer-4-chnnels\": 128,\n",
    "    \"dropout-prob\": 0.2,\n",
    "    \n",
    "}\n",
    "mlf_run.log_params(params_dict)\n",
    "\n",
    "mlf_run.log_model(model, \"keras\")\n",
    "\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833610a9",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = pathlib.Path(\"input/Testing_Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a768ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = len(list(test_data_dir.glob('*/*')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409698b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_driving_license = list(test_data_dir.glob('driving_license/*'))\n",
    "test_social_security = list(test_data_dir.glob('social_security/*'))\n",
    "test_others = list(test_data_dir.glob('others/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539dc818",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_data_dir,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73afd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in test_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8005ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.keras.utils.load_img(\n",
    "    \"input/Testing_Data/others/111.jpg\", target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde4dacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece54752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img_array):\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    class_name = class_names[np.argmax(score)]\n",
    "    return class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4613926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "classes = [test_driving_license, test_social_security, test_others]\n",
    "img_dict = {}\n",
    "\n",
    "img_num = 1\n",
    "for class_files in classes:\n",
    "    for file_path in random.choices(class_files, k=3):\n",
    "        \n",
    "        img = tf.keras.utils.load_img(\n",
    "            file_path, target_size=(img_height, img_width)\n",
    "        )\n",
    "        img_array = tf.keras.utils.img_to_array(img)\n",
    "        \n",
    "        actual = str(file_path).split(\"/\")[-2]\n",
    "        prediction = get_prediction(tf.expand_dims(img_array, 0))\n",
    "        \n",
    "        img_dict[f\"image-{img_num}\"] = mlf.Image(\n",
    "            data_or_path=img_array.astype(\"uint8\"),\n",
    "            caption=\"CNN predictions\",\n",
    "            class_groups={\n",
    "                \"actuals\": actual, \n",
    "                \"predictions\": prediction\n",
    "                },\n",
    "        )\n",
    "        img_num+=1\n",
    "\n",
    "mlf_run.log_images(img_dict)\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928a8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ef903084c5c52a4a91f9ef5ca044f687b322219c655fbb3a0754c14ca2b62b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
